{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpgm.mpgm.evaluation.generating_samples import *\n",
    "from mpgm.mpgm.models.SPGM import SPGM\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import sympy\n",
    "import cvxopt\n",
    "import qpsolvers\n",
    "import qpoases\n",
    "from quadprog import solve_qp\n",
    "\n",
    "from typing import Dict, Optional, Any\n",
    "\n",
    "from mpgm.mpgm.model_fitters.prox_grad_fitters import Prox_Grad_Fitter, Constrained_Prox_Grad_Fitter\n",
    "from mpgm.mpgm.model_fitters.prox_operators import QuadProgOperator\n",
    "\n",
    "import scipy\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcio/miniconda3/envs/mpgm/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "100%|██████████| 22401/22401 [00:19<00:00, 1128.91it/s]\n"
     ]
    }
   ],
   "source": [
    "gg = RandomNmGraphGenerator(10)\n",
    "wa = Bimodal_Gaussian_Weight_Assigner(mean_1=-0.1,\n",
    "                                     std_1=0.02,\n",
    "                                     mean_2=0.1,\n",
    "                                     std_2=0.02,\n",
    "                                     split=0.4)\n",
    "np.random.seed(0)\n",
    "    \n",
    "G = gg.generate_graph(nr_variables=10)\n",
    "wa.assign_weights(G)\n",
    "model = TPGM(R=10, theta=G)\n",
    "sampler = TPGMGibbsSampler(burn_in=50, thinning_nr=150)\n",
    "    \n",
    "samples = sampler.generate_samples(model, np.zeros((10, )), 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for ii in range(10):\n",
    "    print(G[ii, ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SPGM(R=10, R0=5)\n",
    "\n",
    "nr_variables = 10\n",
    "theta_init = np.random.normal(0, 0.1, (nr_variables, nr_variables))\n",
    "np.fill_diagonal(theta_init, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'keep_diags_zero'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-07b12e106d63>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m fitter = Prox_Grad_Fitter(alpha=0.8,\n\u001B[0m\u001B[1;32m      2\u001B[0m                           \u001B[0maccelerated\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m                           \u001B[0msave_regularization_paths\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m                           \u001B[0minit_step_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m                           \u001B[0mearly_stop_criterion\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'likelihood'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: __init__() got an unexpected keyword argument 'keep_diags_zero'"
     ]
    }
   ],
   "source": [
    "fitter = Prox_Grad_Fitter(alpha=0.8,\n",
    "                          accelerated=True,\n",
    "                          save_regularization_paths=False,\n",
    "                          init_step_size=0.1,\n",
    "                          early_stop_criterion='likelihood',\n",
    "                          keep_diags_zero=True)\n",
    "# a,b,c,d,e = fitter.fit_node(1, model.calculate_nll, model.calculate_grad_nll, samples, theta_init)\n",
    "ret = fitter.call_fit_node(model.calculate_nll, model.calculate_grad_nll, samples, theta_init, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpgm.mpgm.evaluation.evaluation_metrics import EvalMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvalMetrics.calculate_MSEs(ret[0], G, EvalMetrics.SymmModes.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_variables = 10\n",
    "nr_iterations = len(e)\n",
    "print(nr_iterations)\n",
    "for ii in range(nr_variables):\n",
    "    plt.plot(list(range(nr_iterations)), e[:,ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def solve_constrained_prox_grad_gaines(objective:np.ndarray, data:np.ndarray, reg_param:float):\n",
    "# Decided not to pursue this, as this is a path regularizer + start parameters are initialised\n",
    "# using QP anyway.\n",
    "\n",
    "# The question remains: is QP faster than the path method? (even for small params)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def prox_operator_cvxopt(data_points:np.ndarray, objective:np.ndarray, reg_parameter:float) -> np.ndarray:\n",
    "        print('Before: alpha=' + str(reg_parameter) + ' ' + str(objective))\n",
    "        if True:\n",
    "            n = len(objective)\n",
    "\n",
    "            v = objective.reshape((n, 1))\n",
    "            alpha = reg_parameter\n",
    "            q = alpha * np.ones((2 * n, 1)) - np.vstack([v, -v])\n",
    "\n",
    "            # The order of operations is: C -> -C -> (C, -C) -> add one row to it, ensuring positivity of beta aka a\n",
    "            # row of -1s; d is 2n x 1 of 0s.\n",
    "            C = data_points\n",
    "            xC, yC = C.shape\n",
    "            C = -C  # Since we want our ineq to be greater than or equal to zero.\n",
    "            G = np.hstack([C, -C])\n",
    "\n",
    "            # Not sure if this will work.\n",
    "            G = np.vstack([G, -np.ones((1, 2 * yC))])\n",
    "            print(G.shape)\n",
    "            G = Constrained_Prox_Grad_Fitter.remove_dependent_rows(G)\n",
    "            print(G.shape)\n",
    "            h = np.zeros((G.shape[0], 1))\n",
    "\n",
    "            P = np.zeros((2 * n, 2 * n))\n",
    "            P[0:n, 0:n] = np.identity(n)\n",
    "            P[n:2 * n, 0:n] = -np.identity(n)\n",
    "            P[0:n, n:2 * n] = -np.identity(n)\n",
    "            P[n:2 * n, n:2 * n] = np.identity(n)\n",
    "\n",
    "            P = cvxopt.matrix(P, tc='d')\n",
    "            q = cvxopt.matrix(q, tc='d')\n",
    "            G = cvxopt.matrix(G, tc='d')\n",
    "            h = cvxopt.matrix(h, tc='d')\n",
    "            solution = cvxopt.solvers.qp(P, q, G, h, kktsolver='ldl', options={'kktreg': 1e-9, 'show_progress': False,\n",
    "                                                                               'maxiters': 500})\n",
    "\n",
    "            beta_2n = np.array(solution['x']).reshape((2 * n,))\n",
    "            beta = beta_2n[:n] - beta_2n[n:]\n",
    "\n",
    "            print(\"After: \" + str(beta))\n",
    "            print(\"Status: \" + str(solution['status'] + ' ' + str(solution['iterations'])))\n",
    "            return beta, beta_2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "objective = np.zeros((10, ))\n",
    "objective[0] = 1\n",
    "beta = prox_operator_osqp(samples, objective, reg_parameter=1)\n",
    "print(beta2n)\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox_operator_quadprog(data_points:np.ndarray, objective:np.ndarray, reg_parameter:float) -> np.ndarray:\n",
    "    print('Before: alpha=' + str(reg_parameter) + ' ' + str(objective))\n",
    "    if True:\n",
    "        n = len(objective)\n",
    "\n",
    "        v = objective.reshape((n, 1))\n",
    "        alpha = reg_parameter\n",
    "        q = alpha * np.ones((2*n, 1)) - np.vstack([v, -v])\n",
    "        q = q.reshape((2*n, ))\n",
    "\n",
    "        # The order of operations is: C -> -C -> (C, -C) -> add one row to it, ensuring positivity of beta aka a\n",
    "        # row of -1s; d is 2n x 1 of 0s.\n",
    "        C = data_points\n",
    "        xC, yC = C.shape\n",
    "        G = np.hstack([C, -C])\n",
    "\n",
    "        # Not sure if this will work.\n",
    "        G = np.vstack([G, np.ones((1, 2 * yC))])\n",
    "        G = Constrained_Prox_Grad_Fitter.remove_dependent_rows(G)\n",
    "        h = np.zeros((G.shape[0],))\n",
    "\n",
    "        P = np.zeros((2*n, 2*n))\n",
    "        P[0:n, 0:n] = np.identity(n)\n",
    "        P[n:2*n, 0:n] = -np.identity(n)\n",
    "        P[0:n, n:2*n] = -np.identity(n)\n",
    "        P[n:2*n, n:2*n] = np.identity(n)\n",
    "\n",
    "        print(G.shape)\n",
    "        solution = solve_qp(P, -q, G.T, h)\n",
    "        print(solution)\n",
    "\n",
    "        beta_2n = np.array(solution['x']).reshape((2 * n,))\n",
    "        beta = beta_2n[:n] - beta_2n[n:]\n",
    "\n",
    "        print(\"After: \" + str(beta))\n",
    "        print(\"Status: \" + str(solution['status'] + ' ' + str(solution['iterations'])))\n",
    "        return beta \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox_operator_qpoases(data_points:np.ndarray, objective:np.ndarray, reg_parameter:float) -> np.ndarray:\n",
    "    print('Before: alpha=' + str(reg_parameter) + ' ' + str(objective))\n",
    "    if True:\n",
    "        n = len(objective)\n",
    "\n",
    "        v = objective.reshape((n, 1))\n",
    "        alpha = reg_parameter\n",
    "\n",
    "        q = alpha * np.ones((2*n, 1)) - np.vstack([v, -v])\n",
    "        q = q.reshape((2*n, ))\n",
    "\n",
    "        # The order of operations is: C -> -C -> (C, -C) -> add one row to it, ensuring positivity of beta aka a\n",
    "        # row of -1s; d is 2n x 1 of 0s.\n",
    "        C = data_points\n",
    "        xC, yC = C.shape\n",
    "        C = -C  # Since we want our ineq to be greater than or equal to zero.\n",
    "        G = np.hstack([C, -C])\n",
    "\n",
    "        # Not sure if this will work.\n",
    "        G = np.vstack([G, -np.identity(2*yC)])\n",
    "        print(G.shape)\n",
    "#         G = QuadProgOperator.remove_dependent_rows(G)\n",
    "#         print(G.shape)\n",
    "        h = np.zeros((G.shape[0], ))\n",
    "\n",
    "        P = np.zeros((2 * n, 2 * n))\n",
    "        P[0:n, 0:n] = np.identity(n)\n",
    "        P[n:2 * n, 0:n] = -np.identity(n)\n",
    "        P[0:n, n:2 * n] = -np.identity(n)\n",
    "        P[n:2 * n, n:2 * n] = np.identity(n)\n",
    "        \n",
    "        solution = qpsolvers.qpoases_solve_qp(P, q, G, h)\n",
    "        print(solution)\n",
    "\n",
    "        beta_2n = solution.reshape((2 * n,))\n",
    "        beta = beta_2n[:n] - beta_2n[n:]\n",
    "\n",
    "        print(\"After: \" + str(beta))\n",
    "        return beta, beta_2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox_operator_osqp(data_points:np.ndarray, objective:np.ndarray, reg_parameter:float) -> np.ndarray:\n",
    "    print('Before: alpha=' + str(reg_parameter) + ' ' + str(objective))\n",
    "    if True:\n",
    "        n = len(objective)\n",
    "\n",
    "        v = objective.reshape((n, 1))\n",
    "        alpha = reg_parameter\n",
    "\n",
    "        q = alpha * np.ones((2*n, 1)) - np.vstack([v, -v])\n",
    "        q = q.reshape((2*n, ))\n",
    "\n",
    "        # The order of operations is: C -> -C -> (C, -C) -> add one row to it, ensuring positivity of beta aka a\n",
    "        # row of -1s; d is 2n x 1 of 0s.\n",
    "        C = data_points\n",
    "        xC, yC = C.shape\n",
    "        C = -C  # Since we want our ineq to be greater than or equal to zero.\n",
    "        G = np.hstack([C, -C])\n",
    "\n",
    "        # Not sure if this will work.\n",
    "        G = np.vstack([G, -np.identity(2*yC)])\n",
    "        print(G.shape)\n",
    "#         G = Constrained_Prox_Grad_Fitter.remove_dependent_rows(G)\n",
    "#         print(G.shape)\n",
    "        h = np.zeros((G.shape[0], ))\n",
    "\n",
    "        P = np.zeros((2*n, 2*n))\n",
    "        P[0:n, 0:n] = np.identity(n)\n",
    "        P[n:2 * n, 0:n] = -np.identity(n)\n",
    "        P[0:n, n:2 * n] = -np.identity(n)\n",
    "        P[n:2 * n, n:2 * n] = np.identity(n)\n",
    "        \n",
    "        solution = qpsolvers.osqp_solve_qp(P, q, G, h)\n",
    "        print(solution)\n",
    "\n",
    "        beta_2n = solution.reshape((2 * n,))\n",
    "        beta = beta_2n[:n] - beta_2n[n:]\n",
    "\n",
    "        print(\"After: \" + str(beta))\n",
    "        return beta, beta_2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.identity(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = np.zeros((10, ))\n",
    "objective[0] = 1\n",
    "beta, beta2n = prox_operator_qpoases(samples, objective, reg_parameter=2)\n",
    "print(beta2n)\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to write + test a projection operator onto the intersection of halfspaces.\n",
    "# scipy.optimize.minimize? How fast is it?\n",
    "def l2norm(x:np.ndarray, objective:np.ndarray, reg_param:float) -> float:\n",
    "    sq_norm = (x-objective)**2\n",
    "    return np.sum(sq_norm) * 1/(2 * reg_param)\n",
    "\n",
    "def jac_l2norm(x:np.ndarray, objective:np.ndarray, reg_param:float) -> np.ndarray:\n",
    "    return (x-objective)/reg_param\n",
    "\n",
    "# def constraint(x:np.ndarray, data_point:np.ndarray, node):\n",
    "#     inequality_lh = np.dot(x, data_point) - x[node] * data_point[node] + x[node]\n",
    "#     return inequality_lh >= 0\n",
    "\n",
    "# def constraint_jac(x:np.ndarray, data_point:np.ndarray, node:int) -> np.ndarray:\n",
    "#     jac = np.array(data_point)\n",
    "#     jac[node] = 1\n",
    "#     return jac\n",
    "\n",
    "# def construct_constraints(data:np.ndarray, node:int) -> Dict[Any, Any]:\n",
    "#     dict_seq = []\n",
    "#     reduced_data = Constrained_Prox_Grad_Fitter.remove_dependent_rows(data)\n",
    "#     for ii in range(reduced_data.shape[0]):\n",
    "#         data_point = reduced_data[ii, :]\n",
    "#         constraint_dict = dict()\n",
    "#         constraint_dict['type'] = 'ineq'\n",
    "#         constraint_dict['fun'] = partial(constraint, data_point=data_point, node=node)\n",
    "#         constraint_dict['jac'] = partial(constraint_jac, data_point=data_point, node=node)\n",
    "#         dict_seq.append(constraint_dict)\n",
    "#     return dict_seq\n",
    "\n",
    "def construct_constraints(data:np.ndarray, node:int):\n",
    "    A = np.copy(data)\n",
    "    A[:, node] = 1\n",
    "    constraints = scipy.optimize.LinearConstraint(A, 0, np.inf, keep_feasible=False)\n",
    "    return constraints\n",
    "\n",
    "def soft_thresholding_operator(objective:np.ndarray, reg_parameter:float) -> np.ndarray:\n",
    "    obj_plus = objective - reg_parameter\n",
    "    obj_minus = objective + reg_parameter\n",
    "    return obj_plus * (obj_plus > 0) + obj_minus * (obj_minus < 0)\n",
    "\n",
    "# Disagree with this.\n",
    "def check_convergence(x:np.ndarray, z:np.ndarray, threshold:Optional[float]=1e-3):\n",
    "    converged_params = (x - z) ** 2 <= (threshold ** 2) * (x ** 2)\n",
    "    all_converged = all(converged_params)\n",
    "    return all_converged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox_operator_admm(data_points:np.ndarray, \n",
    "                       objective:np.ndarray, \n",
    "                       reg_parameter:float, \n",
    "                       node:int, \n",
    "                       tau:Optional[float]=0.1,\n",
    "                       min_iter:Optional[int]=100,\n",
    "                       max_iter:Optional[int]=1000) -> np.ndarray:\n",
    "    n = len(objective)\n",
    "    u = np.zeros((n,))\n",
    "    z = np.copy(objective)\n",
    "    x = np.copy(objective)\n",
    "    \n",
    "    new_reg_parameter = reg_parameter/(1+tau)\n",
    "    \n",
    "    f_operator = partial(soft_thresholding_operator, \n",
    "                         reg_parameter=new_reg_parameter)\n",
    "    \n",
    "    # Need to specify: x0, jac and fun.\n",
    "    g_operator = partial(scipy.optimize.minimize, \n",
    "                         method=\"SLSQP\",\n",
    "                         constraints=construct_constraints(data_points, node))\n",
    "    \n",
    "    # Found bug: this flavor of ADMM makes x converge to -z. \n",
    "    # Since z is the result of g_operator, keeping constraints true for x, means\n",
    "    # multiplying them by -1 to keep them true for z (if it makes sense).\n",
    "    \n",
    "    # STOOOPID.\n",
    "    \n",
    "    iteration = 0\n",
    "    while (iteration <= min_iter or not check_convergence(x, z)) and iteration <= max_iter:\n",
    "        print(iteration)\n",
    "        \n",
    "        prior_lasso_objective = (objective + tau*(z-u))/(1+tau)\n",
    "        \n",
    "        print(prior_lasso_objective)\n",
    "        \n",
    "        x = f_operator(prior_lasso_objective)\n",
    "        \n",
    "        fun = partial(l2norm, objective=x+u, reg_param=1.0)\n",
    "        jac = partial(jac_l2norm, objective=x+u, reg_param=1.0)\n",
    "        z = g_operator(x0=(x+u), fun=fun, jac=jac)['x']\n",
    "        \n",
    "        u = u + x - z\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        print(x)\n",
    "        print(z)\n",
    "    \n",
    "    return x, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = np.random.normal(0, 0.1, (10, ))\n",
    "objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, z = prox_operator_admm(data_points=samples,\n",
    "                      objective=objective,\n",
    "                      reg_parameter=0.01,\n",
    "                      node=0,\n",
    "                      max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x + z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linprog\n",
    "import numpy as np\n",
    "\n",
    "c = np.zeros(6)\n",
    "c[5] = 1\n",
    "A = np.array([[1, 2, 7, 2, 4],\n",
    "             [0, 0, 9, 6, 2],\n",
    "             [7, 9, 4, 5, 3],\n",
    "             [1, 4, 0, 7, 9],\n",
    "             [9, 7, 3, 8, 3]])\n",
    "A_ub = np.hstack((A, -np.ones((5,1))))\n",
    "b_ub = np.zeros(5)\n",
    "\n",
    "A_eq = np.ones((1, 6))\n",
    "A_eq[0, 5] = 0\n",
    "b_eq = np.ones(1)\n",
    "\n",
    "# Default bounds are (0, None).\n",
    "x = linprog(c, A_ub, b_ub, A_eq, b_eq)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox(objective: np.ndarray, reg_parameter: float, node: int, data_points: np.ndarray) -> np.ndarray:\n",
    "    obj_plus = objective - reg_parameter\n",
    "    obj_minus = objective + reg_parameter\n",
    "    return obj_plus * (obj_plus > 0) + obj_minus * (obj_minus < 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.array([0.5, 0.6, 0.7, 1])\n",
    "print(prox(s, 0.6, 0, np.array([])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.identity(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L[9,0] = 1\n",
    "L[8,3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L * L.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_sparse_spd_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = make_sparse_spd_matrix(dim=10,\n",
    "                          alpha=0.9,\n",
    "                          norm_diag=False,\n",
    "                          smallest_coef=0.1,\n",
    "                          largest_coef=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}